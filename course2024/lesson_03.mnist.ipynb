{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training a Digit Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "\n",
    "len(three_tensors), len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "\n",
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(dim=1)\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x, train_y))\n",
    "x, y = dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "\n",
    "valid_3_tens.shape, valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 5,  9,  8, 15,  4]),\n",
       " tensor([16,  0, 12, 18,  6]),\n",
       " tensor([19,  3, 17, 11,  1]),\n",
       " tensor([ 2, 13,  7, 10, 14])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = range(20)\n",
    "dl = DataLoader(coll, batch_size=5, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0):\n",
    "    return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), torch.Size([1, 784]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape, weights.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb): \n",
    "    return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6082],\n",
       "        [ 7.4005],\n",
       "        [-2.3684],\n",
       "        [-8.6094]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element is the same as we calculated before, as we'd expect. This equation, `batch@weights + bias`, is one of the two fundamental equations of any neural network (the other one is the *activation function*, which we'll see in a moment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a mini-batch of size 4 for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward() # add gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0102), tensor([-0.0715]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.shape, weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to check how we're doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0. So our accuracy for each item can be calculated (using broadcasting, so no loops!) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "(preds>0.0).float() == train_y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us this function to calculate our validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then put the batches together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6733"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's our starting point. Let's train for one epoch, and see if the accuracy improves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8632"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914 0.9325 0.9457 0.9545 0.9623 0.9653 0.9677 0.9687 0.9687 0.9706 0.9736 0.9745 0.9745 0.9755 0.9755 0.976 0.9765 0.9765 0.977 0.977 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is such a general foundation, PyTorch provides some useful classes to make it easier to implement. The first thing we can do is replace our `linear1` function with PyTorch's `nn.Linear` module. A *module* is an object of a class that inherits from the PyTorch `nn.Module` class. Objects of this class behave identically to standard Python functions, in that you can call them using parentheses and they will return the activations of a model.\n",
    "\n",
    "`nn.Linear` does the same thing as our `init_params` and `linear` together. It contains both the *weights* and *biases* in a single class. Here's how we replicate our model from the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(28*28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every PyTorch module knows what parameters it has that can be trained; they are available through the `parameters` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = linear.parameters()\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this information to create an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self, params, lr): \n",
    "        self.params, self.lr = list(params), lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create our optimizer by passing in the model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training loop can now be simplified to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our validation function doesn't need to change at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put our little training loop in a function, to make things simpler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are the same as in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 0.6255 "
     ]
    }
   ],
   "source": [
    "train_model(linear, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer with fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai provides the `SGD` class which, by default, does the same thing as our `BasicOptim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.8247 0.8467 0.9121 0.9341 0.9477 0.9546 0.9619 0.9658 0.9673 0.9697 0.9726 0.9731 0.9751 0.9761 0.977 0.9775 0.9775 0.9785 0.9785 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai also provides `Learner.fit`, which we can use instead of `train_model`. To create a `Learner` we first need to create a `DataLoaders`, by passing in our training and validation `DataLoader`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Learner` without using an application (such as `vision_learner`) we need to pass in all the elements that we've created in this chapter: the `DataLoaders`, the model, the optimization function (which will be passed the parameters), the loss function, and optionally any metrics to print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call `fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636654</td>\n",
       "      <td>0.503310</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.469368</td>\n",
       "      <td>0.235132</td>\n",
       "      <td>0.788027</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174741</td>\n",
       "      <td>0.158291</td>\n",
       "      <td>0.857704</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.077611</td>\n",
       "      <td>0.098348</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>0.073607</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027814</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>0.949951</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022052</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>0.957311</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.044999</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018147</td>\n",
       "      <td>0.040815</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>0.037708</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there's nothing magic about the PyTorch and fastai classes. They are just convenient pre-packaged pieces that make your life a bit easier! (They also provide a lot of extra functionality we'll be using in future chapters.)\n",
    "\n",
    "With these classes, we can now replace our linear model with a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have a general procedure for optimizing the parameters of a function, and we have tried it out on a very boring function: a simple linear classifier. A linear classifier is very constrained in terms of what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something nonlinear between two linear classifiers—this is what gives us a neural network.\n",
    "\n",
    "Here is the entire definition of a basic neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! All we have in `simple_net` is two linear classifiers with a `max` function between them.\n",
    "\n",
    "Here, `w1` and `w2` are weight tensors, and `b1` and `b2` are bias tensors; that is, parameters that are initially randomly initialized, just like we did in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key point about this is that `w1` has 30 output activations (which means that `w2` must have 30 input activations, so they match). That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that `30` to anything you like, to make the model more or less complex.\n",
    "\n",
    "That little function `res.max(tensor(0.0))` is called a *rectified linear unit*, also known as *ReLU*. We think we can all agree that *rectified linear unit* sounds pretty fancy and complicated... But actually, there's nothing more to it than `res.max(tensor(0.0))`—in other words, replace every negative number with a zero. This tiny function is also available in PyTorch as `F.relu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is that by using more linear layers, we can have our model do more computation, and therefore model more complex functions. But there's no point just putting one linear layer directly after another one, because when we multiply things together and then add them up multiple times, that could be replaced by multiplying different things together and adding them up just once! That is to say, a series of any number of linear layers in a row can be replaced with a single linear layer with a different set of parameters.\n",
    "\n",
    "But if we put a nonlinear function between them, such as `max`, then this is no longer true. Now each linear layer is actually somewhat decoupled from the other ones, and can do its own useful work. The `max` function is particularly interesting, because it operates as a simple `if` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> S: Mathematically, we say the composition of two linear functions is another linear function. So, we can stack as many linear classifiers as we want on top of each other, and without nonlinear functions between them, it will just be the same as one linear classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazingly enough, it can be mathematically proven that this little function can solve any computable problem to an arbitrarily high level of accuracy, if you can find the right parameters for `w1` and `w2` and if you make these matrices big enough. For any arbitrarily wiggly function, we can approximate it as a bunch of lines joined together; to make it closer to the wiggly function, we just have to use shorter lines. This is known as the *universal approximation theorem*. The three lines of code that we have here are known as *layers*. The first and third are known as *linear layers*, and the second line of code is known variously as a *nonlinearity*, or *activation function*.\n",
    "\n",
    "Just like in the previous section, we can replace this code with something a bit simpler, by taking advantage of PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` creates a module that will call each of the listed layers or functions in turn.\n",
    "\n",
    "`nn.ReLU` is a PyTorch module that does exactly the same thing as the `F.relu` function. Most functions that can appear in a model also have identical forms that are modules. Generally, it's just a case of replacing `F` with `nn` and changing the capitalization. When using `nn.Sequential`, PyTorch requires us to use the module version. Since modules are classes, we have to instantiate them, which is why you see `nn.ReLU()` in this example. \n",
    "\n",
    "Because `nn.Sequential` is a module, we can get its parameters, which will return a list of all the parameters of all the modules it contains. Let's try it out! As this is a deeper model, we'll use a lower learning rate and a few more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.299982</td>\n",
       "      <td>0.406330</td>\n",
       "      <td>0.508341</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>0.225071</td>\n",
       "      <td>0.812561</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.078242</td>\n",
       "      <td>0.114284</td>\n",
       "      <td>0.916094</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051944</td>\n",
       "      <td>0.077827</td>\n",
       "      <td>0.941119</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039680</td>\n",
       "      <td>0.061013</td>\n",
       "      <td>0.954367</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033375</td>\n",
       "      <td>0.051462</td>\n",
       "      <td>0.964671</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029718</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027318</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>0.038231</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024219</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023118</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.032599</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021412</td>\n",
       "      <td>0.031342</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020139</td>\n",
       "      <td>0.029322</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.028489</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019142</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.027077</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.026472</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.025922</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017654</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017353</td>\n",
       "      <td>0.024958</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017075</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016572</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.022849</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>0.022098</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>0.021677</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>0.021487</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014761</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014622</td>\n",
       "      <td>0.021140</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014488</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.020831</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>0.020555</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not showing the 40 lines of output here to save room; the training process is recorded in `learn.recorder`, with the table of output stored in the `values` attribute, so we can plot the accuracy over training as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can view the final accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98233562707901"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have something that is rather magical:\n",
    "\n",
    "1. A function that can solve any problem to any level of accuracy (the neural network) given the correct set of parameters\n",
    "1. A way to find the best set of parameters for any function (stochastic gradient descent)\n",
    "\n",
    "This is why deep learning can do things which seem rather magical, such fantastic things. Believing that this combination of simple techniques can really solve any problem is one of the biggest steps that we find many students have to take. It seems too good to be true—surely things should be more difficult and complicated than this? Our recommendation: try it out! We just tried it on the MNIST dataset and you have seen the results. And since we are doing everything from scratch ourselves (except for calculating the gradients) you know that there is no special magic hiding behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to stop at just two linear layers. We can add as many as we want, as long as we add a nonlinearity between each pair of linear layers. As you will learn, however, the deeper the model gets, the harder it is to optimize the parameters in practice. Later in this book you will learn about some simple but brilliantly effective techniques for training deeper models.\n",
    "\n",
    "We already know that a single nonlinearity with two linear layers is enough to approximate any function. So why would we use deeper models? The reason is performance. With a deeper model (that is, one with more layers) we do not need to use as many parameters; it turns out that we can use smaller matrices with more layers, and get better results than we would get with larger matrices, and few layers.\n",
    "\n",
    "That means that we can train the model more quickly, and it will take up less memory. In the 1990s researchers were so focused on the universal approximation theorem that very few were experimenting with more than one nonlinearity. This theoretical but not practical foundation held back the field for years. Some researchers, however, did experiment with deep models, and eventually were able to show that these models could perform much better in practice. Eventually, theoretical results were developed which showed why this happens. Today, it is extremely unusual to find anybody using a neural network with just one nonlinearity.\n",
    "\n",
    "Here is what happens when we train an 18-layer model using the same approach we saw in <<chapter_intro>>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.082089</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = vision_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly 100% accuracy! That's a big difference compared to our simple neural net. But as you'll learn in the remainder of this book, there are just a few little tricks you need to use to get such great results from scratch yourself. You already know the key foundational pieces. (Of course, even once you know all the tricks, you'll nearly always want to work with the pre-built classes provided by PyTorch and fastai, because they save you having to think about all the little details yourself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create your own implementation of `Learner` from scratch, based on the training loop shown in this chapter.\n",
    "1. Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s). This is a significant project and will take you quite a bit of time to complete! You'll need to do some of your own research to figure out how to overcome some obstacles you'll meet on the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
